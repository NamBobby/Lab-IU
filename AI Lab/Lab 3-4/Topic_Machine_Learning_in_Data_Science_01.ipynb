{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Machine_Learning_in_Data_Science_01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N656fROdcXN9"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N656fROdcXN9"
      },
      "source": [
        "# Defined Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXEqlMjecWy0"
      },
      "source": [
        "# Split Train and Test and check shape \n",
        "def SplitDataFrameToTrainAndTest(DataFrame, TrainDataRate, TargetAtt):\n",
        "    # gets a random TrainDataRate % of the entire set\n",
        "    training = DataFrame.sample(frac=TrainDataRate, random_state=1)\n",
        "    # gets the left out portion of the dataset\n",
        "    testing = DataFrame.loc[~DataFrame.index.isin(training.index)]\n",
        "\n",
        "    X_train = training.drop(TargetAtt, 1)\n",
        "    y_train = training[[TargetAtt]]\n",
        "    X_test = testing.drop(TargetAtt, 1)\n",
        "    y_test = testing[[TargetAtt]]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "    \n",
        "def PrintTrainTestInformation(X_train, y_train, X_test, y_test):\n",
        "  print(\"Train rows and columns : \", X_train.shape)\n",
        "  print(\"Test rows and columns : \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EInM3aeycnFC"
      },
      "source": [
        "def NaiveBayesLearning(DataTrain, TargetTrain):\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    NBModel = GaussianNB()\n",
        "    NBModel.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return NBModel\n",
        "\n",
        "def NaiveBayesTesting(NBModel,DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    PredictTest = NBModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "\n",
        "    return Accuracy, PredictTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfKNFIjzcpYj"
      },
      "source": [
        "def LogisticRegressionLearning(DataTrain, TargetTrain):\n",
        "    # Apply the Logistic Regression\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn import metrics\n",
        "    logreg = LogisticRegression()\n",
        "    # training by Logistic Regression\n",
        "    logreg.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return logreg\n",
        "\n",
        "def LogisticRegressionTesting(LRModel,DataTest, TargetTest):\n",
        "    # Testing and calculate the accuracy\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    logreg = LRModel\n",
        "    PredictTest = logreg.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Logistic regression accuracy: {:.3f}'.format(Accuracy))\n",
        "\n",
        "    return Accuracy, PredictTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-NuUgTFcr7X"
      },
      "source": [
        "def RandomForestLearning(DataTrain, TargetTrain):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    rf = RandomForestClassifier()\n",
        "    rf.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return rf\n",
        "\n",
        "def RandomForestTesting(RFModel,DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    PredictTest = RFModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Random Forest Accuracy: {:.3f}'.format(accuracy_score(TargetTest, PredictTest)))\n",
        "\n",
        "    return Accuracy, PredictTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVavqkNSctDX"
      },
      "source": [
        "def SVMLearning(DataTrain, TargetTrain, ClassifierType = \" \"):\n",
        "    from sklearn.svm import SVC\n",
        "    if(ClassifierType == 'Linear'):\n",
        "        svc = SVC(kernel=\"linear\", C=0.025)\n",
        "#         print('SVM Linear processing')\n",
        "    # Radial basis function kernel\n",
        "    elif (ClassifierType == 'RBF'):\n",
        "        svc = SVC(gamma=2, C=1)\n",
        "#         print('SVM RBF processing')\n",
        "    else:\n",
        "        svc = SVC()\n",
        "#         print('SVM Default processing')\n",
        "    svc.fit(DataTrain, TargetTrain.values.ravel())\n",
        "    return svc\n",
        "\n",
        "def SVMTesting(SVMModel, DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    PredictTest = SVMModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Support Vector Machine Accuracy: {:.3f}'.format(accuracy_score(TargetTest, PredictTest)))\n",
        "    return Accuracy, PredictTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CvzhfmscxMa"
      },
      "source": [
        "def KNNLearning(DataTrain, TargetTrain, K = 3):\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    neigh = KNeighborsClassifier(n_neighbors=K)\n",
        "    neigh.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return neigh\n",
        "\n",
        "def KNNTesting(KNNModel,DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    PredictTest = KNNModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('KNN Accuracy: {:.3f}'.format(accuracy_score(TargetTest, PredictTest)))\n",
        "\n",
        "    return Accuracy, PredictTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnKKcc2LcbkO"
      },
      "source": [
        "# **Main Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJGrwuFTcbix"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMpUQuHiaF1B"
      },
      "source": [
        "# import basic libraries \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# import plot libraries \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgIGHMffb_r_"
      },
      "source": [
        "# import ml libraries \n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler \n",
        "from sklearn.model_selection import train_test_split, cross_val_score \n",
        "from sklearn import linear_model, datasets \n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.svm import LinearSVC, SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "kRIevsfXcOe-",
        "outputId": "fb6cb5db-8c92-4a8b-8286-58410fd263b4"
      },
      "source": [
        "# Read data\n",
        "data = pd.read_csv(\"CustomerChurn.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Account length</th>\n",
              "      <th>Area code</th>\n",
              "      <th>International plan</th>\n",
              "      <th>Voice mail plan</th>\n",
              "      <th>Number vmail messages</th>\n",
              "      <th>Total day minutes</th>\n",
              "      <th>Total day calls</th>\n",
              "      <th>Total day charge</th>\n",
              "      <th>Total eve minutes</th>\n",
              "      <th>Total eve calls</th>\n",
              "      <th>Total eve charge</th>\n",
              "      <th>Total night minutes</th>\n",
              "      <th>Total night calls</th>\n",
              "      <th>Total night charge</th>\n",
              "      <th>Total intl minutes</th>\n",
              "      <th>Total intl calls</th>\n",
              "      <th>Total intl charge</th>\n",
              "      <th>Customer service calls</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KS</td>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OH</td>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NJ</td>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OH</td>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OK</td>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  State  Account length  ...  Customer service calls  Churn\n",
              "0    KS             128  ...                       1  False\n",
              "1    OH             107  ...                       1  False\n",
              "2    NJ             137  ...                       0  False\n",
              "3    OH              84  ...                       2  False\n",
              "4    OK              75  ...                       3  False\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPNspGg4dA8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fcc496-3bfc-4829-b52e-af8aa22c7206"
      },
      "source": [
        "# Split Train and Test and check shape \n",
        "data_train, target_train, data_test, target_test = SplitDataFrameToTrainAndTest(data, 0.6, 'Churn')\n",
        "PrintTrainTestInformation(data_train, target_train, data_test, target_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train rows and columns :  (2000, 19)\n",
            "Test rows and columns :  (1333, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X-JmcNvdHF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "10c8c781-18d0-45bb-dda7-0959693f66ae"
      },
      "source": [
        "data_encoder = data.copy()\n",
        "data_encoder['State'] = LabelEncoder().fit_transform(data_encoder['State'])\n",
        "data_encoder['International plan'] = LabelEncoder().fit_transform(data_encoder['International plan'])\n",
        "data_encoder['Voice mail plan'] = LabelEncoder().fit_transform(data_encoder['Voice mail plan'])\n",
        "data_encoder = data_encoder.join(pd.get_dummies(data_encoder['Area code'], prefix='Area_code_'))\n",
        "data_encoder = data_encoder.drop('Area code', axis=1)\n",
        "data_encoder.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Account length</th>\n",
              "      <th>International plan</th>\n",
              "      <th>Voice mail plan</th>\n",
              "      <th>Number vmail messages</th>\n",
              "      <th>Total day minutes</th>\n",
              "      <th>Total day calls</th>\n",
              "      <th>Total day charge</th>\n",
              "      <th>Total eve minutes</th>\n",
              "      <th>Total eve calls</th>\n",
              "      <th>Total eve charge</th>\n",
              "      <th>Total night minutes</th>\n",
              "      <th>Total night calls</th>\n",
              "      <th>Total night charge</th>\n",
              "      <th>Total intl minutes</th>\n",
              "      <th>Total intl calls</th>\n",
              "      <th>Total intl charge</th>\n",
              "      <th>Customer service calls</th>\n",
              "      <th>Churn</th>\n",
              "      <th>Area_code__408</th>\n",
              "      <th>Area_code__415</th>\n",
              "      <th>Area_code__510</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "      <td>137</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>84</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>223.4</td>\n",
              "      <td>98</td>\n",
              "      <td>37.98</td>\n",
              "      <td>220.6</td>\n",
              "      <td>101</td>\n",
              "      <td>18.75</td>\n",
              "      <td>203.9</td>\n",
              "      <td>118</td>\n",
              "      <td>9.18</td>\n",
              "      <td>6.3</td>\n",
              "      <td>6</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19</td>\n",
              "      <td>121</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>218.2</td>\n",
              "      <td>88</td>\n",
              "      <td>37.09</td>\n",
              "      <td>348.5</td>\n",
              "      <td>108</td>\n",
              "      <td>29.62</td>\n",
              "      <td>212.6</td>\n",
              "      <td>118</td>\n",
              "      <td>9.57</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7</td>\n",
              "      <td>2.03</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>24</td>\n",
              "      <td>147</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>79</td>\n",
              "      <td>26.69</td>\n",
              "      <td>103.1</td>\n",
              "      <td>94</td>\n",
              "      <td>8.76</td>\n",
              "      <td>211.8</td>\n",
              "      <td>96</td>\n",
              "      <td>9.53</td>\n",
              "      <td>7.1</td>\n",
              "      <td>6</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>18</td>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>184.5</td>\n",
              "      <td>97</td>\n",
              "      <td>31.37</td>\n",
              "      <td>351.6</td>\n",
              "      <td>80</td>\n",
              "      <td>29.89</td>\n",
              "      <td>215.8</td>\n",
              "      <td>90</td>\n",
              "      <td>9.71</td>\n",
              "      <td>8.7</td>\n",
              "      <td>4</td>\n",
              "      <td>2.35</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>49</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>258.6</td>\n",
              "      <td>84</td>\n",
              "      <td>43.96</td>\n",
              "      <td>222.0</td>\n",
              "      <td>111</td>\n",
              "      <td>18.87</td>\n",
              "      <td>326.4</td>\n",
              "      <td>97</td>\n",
              "      <td>14.69</td>\n",
              "      <td>11.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   State  Account length  ...  Area_code__415  Area_code__510\n",
              "0     16             128  ...               1               0\n",
              "1     35             107  ...               1               0\n",
              "2     31             137  ...               1               0\n",
              "3     35              84  ...               0               0\n",
              "4     36              75  ...               1               0\n",
              "5      1             118  ...               0               1\n",
              "6     19             121  ...               0               1\n",
              "7     24             147  ...               1               0\n",
              "8     18             117  ...               0               0\n",
              "9     49             141  ...               1               0\n",
              "\n",
              "[10 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5csO7L6dKwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12825c93-ef87-4971-d90a-188152397f21"
      },
      "source": [
        "# Split Train and Test and check shape \n",
        "data_train_encoder, target_train_encoder, data_test_encoder, target_test_encoder = SplitDataFrameToTrainAndTest(data_encoder, 0.6, 'Churn')\n",
        "PrintTrainTestInformation(data_train_encoder, target_train_encoder, data_test_encoder, target_test_encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train rows and columns :  (2000, 21)\n",
            "Test rows and columns :  (1333, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ix5d_6vdOLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b625d3cf-7bab-4d8d-c254-6f9643b4dbd8"
      },
      "source": [
        "X_train = data_train_encoder\n",
        "y_train = target_train_encoder\n",
        "X_test = data_test_encoder\n",
        "y_test = target_test_encoder\n",
        "\n",
        "NBModel = NaiveBayesLearning(X_train, y_train)\n",
        "NBAccuracy,NBPredictTest = NaiveBayesTesting(NBModel,X_test, y_test)\n",
        "print('Naive Bayes accuracy: {:.3f}'.format(NBAccuracy))\n",
        "\n",
        "LRModel = LogisticRegressionLearning(X_train, y_train)\n",
        "LRAccuracy,LRPredictTest = LogisticRegressionTesting(LRModel,X_test, y_test)\n",
        "print('Logistic Regression accuracy: {:.3f}'.format(LRAccuracy))\n",
        "\n",
        "RFModel = RandomForestLearning(X_train, y_train)\n",
        "RFAccuracy,RFPredictTest = RandomForestTesting(RFModel,X_test, y_test)\n",
        "print('Random Forest accuracy: {:.6f}'.format(RFAccuracy))\n",
        "\n",
        "LiSVMModel = SVMLearning(X_train, y_train)\n",
        "LiSVMAccuracy,LiSVMPredictTest = SVMTesting(LiSVMModel, X_test, y_test)\n",
        "print('Linear SVM accuracy: {:.6f}'.format(LiSVMAccuracy))\n",
        "\n",
        "RBFSVMModel = SVMLearning(X_train, y_train, 'RBF')\n",
        "RBFSVMAccuracy,RBFSVMPredictTest = SVMTesting(RBFSVMModel, X_test, y_test)\n",
        "print('RBF SVM accuracy: {:.6f}'.format(RBFSVMAccuracy))\n",
        "\n",
        "KNNModel = KNNLearning(X_train, y_train)\n",
        "KNNAccuracy,KNNPredictTest = KNNTesting(KNNModel,X_test, y_test)\n",
        "print('K Nearest Neighbor accuracy: {:.6f}'.format(KNNAccuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.866\n",
            "Logistic Regression accuracy: 0.854\n",
            "Random Forest accuracy: 0.951238\n",
            "Linear SVM accuracy: 0.857464\n",
            "RBF SVM accuracy: 0.857464\n",
            "K Nearest Neighbor accuracy: 0.867217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S1h3qO9eGsj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "aa787be5-c448-4503-d73f-eb47edc823da"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(random_state=1, max_depth=10)\n",
        "model.fit(data_train_encoder,target_train_encoder)\n",
        "\n",
        "print(data_train_encoder.shape)\n",
        "features = data_train_encoder.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[-len(features):]  # top features\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLEQzhqdeK2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2623e5cf-0d83-4236-b384-943d0772db2b"
      },
      "source": [
        "# Get numerical feature importances\n",
        "feature_list = list(data_train_encoder.columns)\n",
        "importances = list(model.feature_importances_)\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "# Print out the feature and importances \n",
        "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable: Total day minutes    Importance: 0.14\n",
            "Variable: Total day charge     Importance: 0.14\n",
            "Variable: Customer service calls Importance: 0.11\n",
            "Variable: International plan   Importance: 0.08\n",
            "Variable: Total intl calls     Importance: 0.08\n",
            "Variable: Total eve minutes    Importance: 0.07\n",
            "Variable: Total eve charge     Importance: 0.07\n",
            "Variable: Total intl minutes   Importance: 0.05\n",
            "Variable: Total intl charge    Importance: 0.05\n",
            "Variable: Number vmail messages Importance: 0.04\n",
            "Variable: Voice mail plan      Importance: 0.03\n",
            "Variable: Total night minutes  Importance: 0.03\n",
            "Variable: Account length       Importance: 0.02\n",
            "Variable: Total day calls      Importance: 0.02\n",
            "Variable: Total night calls    Importance: 0.02\n",
            "Variable: Total night charge   Importance: 0.02\n",
            "Variable: State                Importance: 0.01\n",
            "Variable: Total eve calls      Importance: 0.01\n",
            "Variable: Area_code__408       Importance: 0.0\n",
            "Variable: Area_code__415       Importance: 0.0\n",
            "Variable: Area_code__510       Importance: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GouvGJ8leVJN",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc3999f-5af1-460d-f264-4f72e6bc3ae2"
      },
      "source": [
        "# Split Train and Test and check shape \n",
        "AttSelection = [\"Total day charge\", \"Total day minutes\", \"Customer service calls\", \"International plan\", \"Total eve minutes\",\n",
        "                \"Total intl calls\", \"Total eve charge\", \"Total intl minutes\", \"Total intl charge\", \"Voice mail plan\",\n",
        "                \"Number vmail messages\", \"Total night minutes\", \"Total night calls\", \"Total night charge\",\n",
        "               \"Churn\"]\n",
        "\n",
        "data_train_encoder_feselection02, target_train_encoder_feselection02, data_test_encoder_feselection02, target_test_encoder_feselection02 = SplitDataFrameToTrainAndTest(data_encoder[AttSelection], 0.6, 'Churn')\n",
        "PrintTrainTestInformation(data_train_encoder_feselection02, target_train_encoder_feselection02, data_test_encoder_feselection02, target_test_encoder_feselection02)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train rows and columns :  (2000, 14)\n",
            "Test rows and columns :  (1333, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asJ_39VVeYno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b115b24-1e4f-4e23-9384-d46cc7ed319f"
      },
      "source": [
        "# Retest all traditional classification approaches\n",
        "X_train = data_train_encoder_feselection02\n",
        "y_train = target_train_encoder_feselection02\n",
        "X_test = data_test_encoder_feselection02\n",
        "y_test = target_test_encoder_feselection02\n",
        "\n",
        "NBModel = NaiveBayesLearning(X_train, y_train)\n",
        "NBAccuracy,NBPredictTest = NaiveBayesTesting(NBModel,X_test, y_test)\n",
        "print('Naive Bayes accuracy: {:.6f}'.format(NBAccuracy))\n",
        "\n",
        "LRModel = LogisticRegressionLearning(X_train, y_train)\n",
        "LRAccuracy,LRPredictTest = LogisticRegressionTesting(LRModel,X_test, y_test)\n",
        "print('Logistic Regression accuracy: {:.6f}'.format(LRAccuracy))\n",
        "\n",
        "RFModel = RandomForestLearning(X_train, y_train)\n",
        "RFAccuracy,RFPredictTest = RandomForestTesting(RFModel,X_test, y_test)\n",
        "print('Random Forest accuracy: {:.6f}'.format(RFAccuracy))\n",
        "\n",
        "LiSVMModel = SVMLearning(X_train, y_train)\n",
        "LiSVMAccuracy,LiSVMPredictTest = SVMTesting(LiSVMModel, X_test, y_test)\n",
        "print('Linear SVM accuracy: {:.6f}'.format(LiSVMAccuracy))\n",
        "\n",
        "RBFSVMModel = SVMLearning(X_train, y_train, 'RBF')\n",
        "RBFSVMAccuracy,RBFSVMPredictTest = SVMTesting(RBFSVMModel, X_test, y_test)\n",
        "print('RBF SVM accuracy: {:.6f}'.format(RBFSVMAccuracy))\n",
        "\n",
        "KNNModel = KNNLearning(X_train, y_train)\n",
        "KNNAccuracy,KNNPredictTest = KNNTesting(KNNModel,X_test, y_test)\n",
        "print('K Nearest Neighbor accuracy: {:.6f}'.format(KNNAccuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.864966\n",
            "Logistic Regression accuracy: 0.856714\n",
            "Random Forest accuracy: 0.951988\n",
            "Linear SVM accuracy: 0.857464\n",
            "RBF SVM accuracy: 0.857464\n",
            "K Nearest Neighbor accuracy: 0.885971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxg-pBYqer9p"
      },
      "source": [
        "*Neural Network*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKICaW7GevCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1b41e1-0e75-4c06-9c8b-0ee01fe1ee2f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "## Create our model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st layer: input_dim=21, 12 nodes, RELU\n",
        "model.add(Dense(12, input_dim=21,activation='relu'))\n",
        "# 2nd layer: 8 nodes, RELU\n",
        "model.add(Dense(8,activation='relu'))\n",
        "# output layer: dim=1, activation sigmoid\n",
        "model.add(Dense(1,activation='sigmoid' ))\n",
        "\n",
        "## Model output shape\n",
        "model.output_shape\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Model config\n",
        "model.get_config()\n",
        "\n",
        "# List all weight tensors \n",
        "model.get_weights()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',   # since we are predicting 0/1\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                264       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 377\n",
            "Trainable params: 377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK-hlJvxezfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3127a1de-2ee4-409d-d205-a2b305cfd2e4"
      },
      "source": [
        "# Retest all traditional classification approaches\n",
        "X_train = data_train_encoder\n",
        "y_train = target_train_encoder\n",
        "X_testNN = data_test_encoder\n",
        "y_testNN = target_test_encoder\n",
        "\n",
        "epochs = 500  # num of epochs to test for\n",
        "batch_size = 15\n",
        "\n",
        "# checkpoint: store the best model\n",
        "ckpt_model = 'pima-weights.best.hdf5'\n",
        "checkpoint = ModelCheckpoint(ckpt_model, \n",
        "                            monitor='val_accuracy',\n",
        "                            verbose=1,\n",
        "                            save_best_only=True,\n",
        "                            mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "print('Starting training...')\n",
        "# train the model, store the results for plotting\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data=(X_testNN, y_testNN),\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=callbacks_list,\n",
        "                    verbose=0)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88972, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.88972\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.88972\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.88972\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.88972\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.88972\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.88972 to 0.89272, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.89272\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89272\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.89272 to 0.89422, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89422\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.89422 to 0.89647, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89647\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89647\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89647\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89647\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89647\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89647\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.89647 to 0.89797, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.89797\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.89797 to 0.89872, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.89872\n",
            "\n",
            "Epoch 00159: val_accuracy improved from 0.89872 to 0.90023, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.90023\n",
            "\n",
            "Epoch 00234: val_accuracy improved from 0.90023 to 0.90098, saving model to pima-weights.best.hdf5\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.90098\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.90098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-9b281589ddfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Use cached evaluation data only when it's called in `Model.fit`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       if (getattr(self, '_fit_frame', None) is not None\n\u001b[0;32m-> 1349\u001b[0;31m           \u001b[0;32mand\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m           and getattr(self, '_eval_data_handler', None) is not None):\n\u001b[1;32m   1351\u001b[0m         \u001b[0mdata_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_inspect.py\u001b[0m in \u001b[0;36mcurrentframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;34m\"\"\"TFDecorator-aware replacement for inspect.currentframe.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is not a frame or traceback object'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# or it is in the linecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m                 \u001b[0;31m# Have already mapped this module, so skip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4b7yEWnrddu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a9b052-ebcf-42e5-c285-66e8294f3b1c"
      },
      "source": [
        "y_predNN = model.predict(X_testNN)\n",
        "\n",
        "scoreNN = model.evaluate(X_testNN, y_testNN,verbose=1)\n",
        "\n",
        "print(scoreNN)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2790 - accuracy: 0.8912\n",
            "[0.27899160981178284, 0.8912228345870972]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIk8NJdPrddv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d3a7f1-eefe-46d0-ccc0-2ff16e81a76e"
      },
      "source": [
        "# Import the modules from `sklearn.metrics`\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_matrix(y_testNN,y_predNN.round())\n",
        "#confusion_matrix(y_testNN, y_predNN)\n",
        "# Precision \n",
        "precision_score(y_testNN, y_predNN.round())\n",
        "# Recall\n",
        "recall_score(y_testNN, y_predNN.round())\n",
        "# F1 score\n",
        "f1_score(y_testNN,y_predNN.round())\n",
        "# Cohen's kappa\n",
        "cohen_kappa_score(y_testNN, y_predNN.round())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4616811445664011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO2wNA8nrddv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}